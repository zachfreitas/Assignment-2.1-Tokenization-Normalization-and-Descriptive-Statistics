{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "from lexical_diversity import lex_div as ld\n",
    "import csv\n",
    "import html\n",
    "import textacy.preprocessing as tprep\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e164b5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x29ee3410890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"C:\\\\Users\\\\zfreitas\\\\Dropbox\\\\Classes\\\\USD\\\\ADS-509-01-SP23 - Applied Text Mining\\\\2. Module Two\\\\Assignment 1\\\\M1 Results\\\\\"\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter\\\\\"\n",
    "lyrics_folder = \"lyrics\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = ld.ttr(tokens) # Simple TTR = len(Counter(text))/len(text)\n",
    "    num_characters = sum([len(i) for i in tokens])\n",
    "    \n",
    "    if verbose:        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        print(f\"The {num_tokens} most common tokens\")\n",
    "        print(Counter(tokens).most_common(num_tokens))\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "The 13 most common tokens\n",
      "[('text', 3), ('here', 2), ('example', 2), ('is', 1), ('some', 1), ('with', 1), ('other', 1), ('in', 1), ('this', 1)]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: Assertion statements are a way to make sure your code is working as you expect it to. You create examples that you know to be true and have the answer for. Then you run your code through your predefined examples to make sure it is running as expected.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5b8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary Approach 1 - first\n",
    "\n",
    "# d[artist][title] = “the song lyrics as a string”\n",
    "# d = {}\n",
    "# # Get the directory location\n",
    "# directory = data_location + lyrics_folder\n",
    "# # Get all the subfolders in directory.\n",
    "# artist_subfolders = [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]\n",
    "\n",
    "\n",
    "# # Get all the files in each of the subfolders\n",
    "# for artist in artist_subfolders:\n",
    "#     d[artist] = {}\n",
    "#     for filename in os.listdir(directory + artist):\n",
    "#         f = os.path.join(directory + artist, filename)\n",
    "#         # checking if it is a file\n",
    "#         if os.path.isfile(f):\n",
    "#             with open(f) as file:\n",
    "#                 title = file.readline().strip()\n",
    "#                 d[artist][title] = file.read().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "# Dictionary Approach 2 - Using defaultdict\n",
    "\n",
    "# d[artist][title] = “the song lyrics as a string”\n",
    "lyrics = defaultdict(lambda: defaultdict(str))\n",
    "#  \n",
    "# Get the directory location\n",
    "directory = data_location + lyrics_folder\n",
    "# Get all the subfolders in directory.\n",
    "artist_subfolders = [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]\n",
    "\n",
    "\n",
    "# Get all the files in each of the subfolders\n",
    "for artist in artist_subfolders:\n",
    "    for filename in os.listdir(directory + artist):\n",
    "        f = os.path.join(directory + artist, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            with open(f) as file:\n",
    "                title = file.readline().strip()\n",
    "                lyrics[artist][title] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd8feb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I light a candle in the morning \\nTo signify that your still on my mind\\nDarkness arrived without a warning \\nIt brought me down\\nBut I know the world just keeps on turning\\n\\nI wish that I could turn you on \\nLike a switch in my kitchen \\nRight before dawn\\n88 days seems so long\\nI believe in you and me\\nBut it's so hard to trust\\nSomething you just can't see, still I've got\\n\\n[CHORUS]\\n88 days 'til the sun\\nAnd while you're gone\\nI've got so much work inside my heart to be done, I've got\\n88 days 'til the sun\\nI`ve got to get my spirit ready\\nFor when the springtime comes\\n88 days 'til the sun\\n\\nZip up my thickest jacket \\nI miss the green and the light you gave to me\\nPrepare to get my feet wet\\nHalogen's on bright when 2 pm is like 2 in the night, it ain't right\\nSo what's the message in this song\\nThat the pain doesn't mean that you can't carry on\\nStill 88 days seem so long\\nA meditation, a revelation\\nBut it's so hard to trust\\nSomething you just can't see, still I've got\\n\\n[Chorus (x1)]\\n\\n88 days 'til the sun comes around\\n(You got work, you got work, you got work to be done)\\n88 days 'til the sun comes around\\n(You got work, you got work, you got work to be done)\\nA meditation, a revelation\\nBut it's so hard to trust\\nSomething you just can't see, I've got\\n\\nI've got 88 days, 88 days,\\n(You got work, you got work, you got work to be done)\\nI've got work, I've got work, I've got work to be done\\n(88 days 'til the sun)\\n88 days &lt;scat&gt;\\nGot to get my spirit ready for the springtime\\nStill I've got\\n(88 days 'til the sun)\\n[scat] springtime\\n(You got work, you got work, you got work to be done)\\n88 days 'til the springtime [fade out]\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[\"robyn\"].get('\"88 Days\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "341491fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(lyrics['cher']))\n",
    "print(len(lyrics['robyn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14055f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lyrics Pandas Dataframe for Cleaning\n",
    "artists = ['cher', 'robyn']\n",
    "\n",
    "for i, artist in enumerate(artists):\n",
    "    if i == 0:\n",
    "        lyrics_df = pd.DataFrame(lyrics[artist].items(), columns=['title', 'lyrics'])\n",
    "        lyrics_df['artist'] = artist\n",
    "    lyrics_dfi = pd.DataFrame(lyrics[artist].items(), columns=['title', 'lyrics'])\n",
    "    lyrics_dfi['artist'] = artist\n",
    "    lyrics_df = pd.concat([lyrics_df, lyrics_dfi], ignore_index=True)\n",
    "\n",
    "lyrics_df = lyrics_df.rename({0:\"description\"}, inplace=True,  axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "\n",
    "# Dictionary Approach 2 - Using defaultdict\n",
    "\"\"\"\"For the Twitter data, we only need the description field for this assignment. \n",
    "Feel free all the descriptions read it into a data structure. \n",
    "In the solution, I stored the descriptions as a dictionary of lists, \n",
    "with the key being the artist. \n",
    "\"\"\"\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "# d[artist][title] = “the song lyrics as a string”\n",
    "desc = defaultdict(list)\n",
    "#  \n",
    "artists = ['cher', 'robyn']\n",
    "filename = ['cher_followers_data.txt', 'robynkonichiwa_followers_data.txt']\n",
    "\n",
    "# Get the directory location\n",
    "directory = data_location + twitter_folder\n",
    "\n",
    "# Get all the files in each of the subfolders\n",
    "for i, artist in enumerate(artists):\n",
    "    f = os.path.join(directory, filename[i])\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        with open(f, encoding=\"utf8\") as f:\n",
    "            reader = csv.DictReader(f, delimiter=\"\\t\") # read rows into a dictionary format\n",
    "            for row in reader: # read a row as {column1: value1, column2: value2,...}\n",
    "                for (k,v) in row.items(): # go over each column name and value \n",
    "                    if k == \"description\":\n",
    "                        # append the value into the appropriate list\n",
    "                        # based on column name k                        \n",
    "                        desc[artist].append(v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40c761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pandas Dataframe for Cleaning\n",
    "for i, artist in enumerate(artists):\n",
    "    if i == 0:\n",
    "        twitter_df = pd.DataFrame.from_dict(desc[artist], orient='columns')\n",
    "        twitter_df.rename({0:\"description\"}, inplace=True,  axis=1)\n",
    "        twitter_df['artist'] = artist\n",
    "    twitter_dfi = pd.DataFrame.from_dict(desc[artist])\n",
    "    twitter_dfi.rename({0:\"description\"}, inplace=True,  axis=1)\n",
    "    twitter_dfi['artist'] = artist\n",
    "    twitter_df = pd.concat([twitter_df, twitter_dfi], ignore_index=True)\n",
    "\n",
    "\n",
    "twitter_df = twitter_df.fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7911682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions - Cleaning data\n",
    "\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # Remove Puncuation\n",
    "    def remove_punc(s):\n",
    "        return ''.join(ch for ch in s if ch not in punctuation)\n",
    "    text = remove_punc(text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    text = tprep.normalize_hyphenated_words(text)\n",
    "    text = tprep.normalize_quotation_marks(text)\n",
    "    text = tprep.normalize_unicode(text)\n",
    "    text = tprep.remove_accents(text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b327033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>cher</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 &amp; 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "      <td>cher</td>\n",
       "      <td>𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "      <td>cher</td>\n",
       "      <td>163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csu</td>\n",
       "      <td>cher</td>\n",
       "      <td>csu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>cher</td>\n",
       "      <td>Writer Washinformer SpelmanCollege alumna DCna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184476</th>\n",
       "      <td>singer of songs, type 1 diabetic, tired $jakel...</td>\n",
       "      <td>robyn</td>\n",
       "      <td>singer of songs type 1 diabetic tired jakelgil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184477</th>\n",
       "      <td>Dadx2/ Con-Arch/ Photographer/ DK #stemgrønnes...</td>\n",
       "      <td>robyn</td>\n",
       "      <td>Dadx2 ConArch Photographer DK stemgrønnest grø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184478</th>\n",
       "      <td>A year to change a life is still a year ✨😌</td>\n",
       "      <td>robyn</td>\n",
       "      <td>A year to change a life is still a year ✨😌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184479</th>\n",
       "      <td>Head of Consumer - Mango. Made in Melbourne. R...</td>\n",
       "      <td>robyn</td>\n",
       "      <td>Head of Consumer Mango Made in Melbourne Rambl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184480</th>\n",
       "      <td>Stand for what is right, even if you stand alone.</td>\n",
       "      <td>robyn</td>\n",
       "      <td>Stand for what is right even if you stand alone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8184481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description artist  \\\n",
       "0                                                            cher   \n",
       "1                 𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 & 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜   cher   \n",
       "2                163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡   cher   \n",
       "3                                                      csu   cher   \n",
       "4        Writer @Washinformer @SpelmanCollege alumna #D...   cher   \n",
       "...                                                    ...    ...   \n",
       "8184476  singer of songs, type 1 diabetic, tired $jakel...  robyn   \n",
       "8184477  Dadx2/ Con-Arch/ Photographer/ DK #stemgrønnes...  robyn   \n",
       "8184478         A year to change a life is still a year ✨😌  robyn   \n",
       "8184479  Head of Consumer - Mango. Made in Melbourne. R...  robyn   \n",
       "8184480  Stand for what is right, even if you stand alone.  robyn   \n",
       "\n",
       "                                         clean_description  \n",
       "0                                                           \n",
       "1                   𝙿𝚛𝚘𝚞𝚍 𝚜𝚞𝚙𝚙𝚘𝚛𝚝𝚎𝚛 𝚘𝚏 𝚖𝚎𝚜𝚜𝚢 𝚋𝚞𝚗𝚜 𝚕𝚎𝚐𝚐𝚒𝚗𝚐𝚜  \n",
       "2                163㎝／愛かっぷ💜26歳🍒 工〇好きな女の子💓 フォローしてくれたらDMします🧡  \n",
       "3                                                      csu  \n",
       "4        Writer Washinformer SpelmanCollege alumna DCna...  \n",
       "...                                                    ...  \n",
       "8184476  singer of songs type 1 diabetic tired jakelgil...  \n",
       "8184477  Dadx2 ConArch Photographer DK stemgrønnest grø...  \n",
       "8184478         A year to change a life is still a year ✨😌  \n",
       "8184479  Head of Consumer Mango Made in Melbourne Rambl...  \n",
       "8184480    Stand for what is right even if you stand alone  \n",
       "\n",
       "[8184481 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create your clean twitter data here\n",
    "\n",
    "twitter_df['clean_description'] = twitter_df['description'].map(clean)\n",
    "\n",
    "twitter_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0f22e10",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# create your clean lyrics data here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m lyrics_df\u001b[39m.\u001b[39;49mcolumns()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# create your clean lyrics data here\n",
    "\n",
    "lyrics_df.columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls to descriptive_stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: \n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"❤️\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lyric length comparison chart here. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b33cfd37f5195bd7836c1451c6eaacc84fbbad3c54541ec8bad2790bfb3f777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
